# Full Pipeline Configuration for World University Scraper

# General settings
general:
  output_dir: 'data/pipeline_results'
  log_level: 'INFO'

# Basic scraper settings (for compatibility)
scraper:
  type: 'selenium'
  request_delay: 3
  max_retries: 3

# Selenium settings (for compatibility)
selenium:
  headless: true
  page_load_timeout: 60
  wait_timeout: 15

# Parser settings (for compatibility)
parser:
  type: 'rankings'

# Sub-configuration files for different components
rankings_config: 'config/default_selenium.yml'
university_config: 'config/university_detail.yml'

# ðŸ”¥ CONFIGURACIÃ“N DE POSTGRESQL (CORREGIDA)
postgres:
  enabled: true
  auto_insert: true
  host: 'localhost'
  port: 5432
  database: 'scrap_db'
  user: 'postgres'
  password: 'postgres'
  if_exists: 'append' # append, replace, fail

# Data processing settings
processor:
  handle_missing_values: true
  normalize_scores: true
  min_score_threshold: 0
  max_score_threshold: 100
  deduplicate: true
  sort_by_rank: true

# Storage settings
storage:
  save_raw: true
  save_processed: true
  save_combined: true
  compress: true
  format: 'pickle'
  create_backup: true
  backup_dir: 'data/backups'

# Export settings
exporters:
  # CSV export
  csv:
    enabled: true
    output_dir: 'data/exports/csv'
    filename: 'university_rankings_{timestamp}.csv'
    index: false
    encoding: 'utf-8'
    sep: ','

  # JSON export
  json:
    enabled: true
    output_dir: 'data/exports/json'
    filename: 'university_data_{timestamp}.json'
    pretty_print: true
    ensure_ascii: false
    include_metadata: true

  # Excel export
  excel:
    enabled: false
    output_dir: 'data/exports/excel'
    filename: 'university_data_{timestamp}.xlsx'
    sheet_name: 'University_Data'
    include_summary: true
    index: false

  # ðŸ”¥ POSTGRESQL EXPORT (CONFIGURACIÃ“N CORREGIDA)
  postgres:
    enabled: true
    auto_insert: true
    host: 'localhost'
    port: 5432
    database: 'scrap_db' # âœ… CORREGIDO
    user: 'postgres' # âœ… CORREGIDO
    password: 'postgres' # âœ… CORREGIDO (o usar variable de entorno)

    # Table settings
    table_name: 'university_rankings'
    schema: 'public'

    # Export options
    if_exists: 'append' # Options: replace, append, fail
    index: false
    method: 'multi'
    chunksize: 1000

# Pipeline execution settings
pipeline:
  continue_on_error: true
  save_intermediate_results: true
  university_batch_size: 50
  max_concurrent_requests: 3
  max_retries: 3
  retry_delay: 5
  min_success_rate: 0.7

# Validation settings
validation:
  required_fields:
    rankings:
      - 'rank'
      - 'name'
      - 'country'
    universities:
      - 'name'
      - 'url'
  check_duplicate_names: true
  check_rank_sequence: true
  check_score_ranges: true
  detect_outliers: true
  outlier_threshold: 3

# Environment-specific overrides
environments:
  development:
    general:
      log_level: 'DEBUG'
    pipeline:
      university_batch_size: 10
    exporters:
      postgres:
        enabled: true # âœ… Habilitado para desarrollo
      csv:
        enabled: true

  production:
    general:
      log_level: 'INFO'
    pipeline:
      university_batch_size: 100
    exporters:
      postgres:
        enabled: true
      csv:
        enabled: true
